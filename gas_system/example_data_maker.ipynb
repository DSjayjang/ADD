{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98250b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved synthetic_sensor_data.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 파라미터 설정\n",
    "num_sensors = 12       # 센서 개수\n",
    "t_end = 10000          # 총 시간(초)\n",
    "time = np.arange(0, t_end + 1)  # 0~480초\n",
    "change_point = 2000      # 변화점 시각(초)\n",
    "peak_time = 240        # 피크 시각(초)\n",
    "noise_std = 0.1        # 노이즈 표준편차\n",
    "\n",
    "# 시드 고정 (재현성)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 데이터 생성\n",
    "sensor_data = {}\n",
    "for i in range(num_sensors):\n",
    "    amp = np.random.uniform(1.0, 2.0)  # 센서별 피크 진폭\n",
    "    signal = np.zeros_like(time, dtype=float)\n",
    "\n",
    "    # 램프업 구간\n",
    "    ramp_mask = (time >= change_point) & (time <= peak_time)\n",
    "    signal[ramp_mask] = amp * (time[ramp_mask] - change_point) / (peak_time - change_point)\n",
    "\n",
    "    # 디케이 구간\n",
    "    decay_mask = time > peak_time\n",
    "    signal[decay_mask] = amp * (1 - (time[decay_mask] - peak_time) / (t_end - peak_time))\n",
    "    signal[decay_mask] = np.clip(signal[decay_mask], 0, None)\n",
    "\n",
    "    # 노이즈 추가 및 음수 클리핑\n",
    "    noise = np.random.normal(scale=noise_std, size=signal.shape)\n",
    "    values = np.clip(signal + noise, 0, None)\n",
    "\n",
    "    sensor_data[f'sensor_{i+1}'] = values\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(sensor_data, index=time)\n",
    "df.index.name = 'time(s)'\n",
    "\n",
    "# CSV로 저장\n",
    "df.to_csv('E:\\INHA\\BS\\gas_system\\synthetic_sensor_data.csv', index=True)\n",
    "\n",
    "print(\"Saved synthetic_sensor_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eefd2c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3333f07",
   "metadata": {},
   "source": [
    "# MiniROCKET Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1877bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIMJUNHEE\\anaconda3\\envs\\gas_system_37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ MiniRocketClassifier 학습 시작...\n",
      "✅ 모델 저장 완료: models/minirocket/minirocket.pkl\n"
     ]
    }
   ],
   "source": [
    "# train_minirocket.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from core.dataset import create_training_windows\n",
    "from models.load_base_models import minirocket\n",
    "\n",
    "def load_data_long(file_path: str):\n",
    "    \"\"\"\n",
    "    time,Variable,Value,Label 형태의 long-format CSV를\n",
    "    (n_samples, n_features) 배열과 라벨 벡터로 변환합니다.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    pivot = df.pivot_table(\n",
    "        index=[\"time\", \"Label\"],\n",
    "        columns=\"Variable\",\n",
    "        values=\"Value\",\n",
    "        aggfunc=\"first\"\n",
    "    ).sort_index()\n",
    "    X_raw = pivot.to_numpy(dtype=float)\n",
    "    y_raw = np.array([lab for (_, lab) in pivot.index], dtype=int)\n",
    "    return X_raw, y_raw\n",
    "\n",
    "def main():\n",
    "    # 1) 데이터 로드\n",
    "    data_path = \"data/Et_H_CO.csv\"\n",
    "    X_raw, y_raw = load_data_long(data_path)\n",
    "\n",
    "    # 2) 슬라이딩 윈도우 생성 (window_size=5, step=1)\n",
    "    window_size = 5\n",
    "    X_train, y_train = create_training_windows(X_raw, y_raw, window_size=window_size)\n",
    "\n",
    "    # 3) MiniRocketClassifier 학습\n",
    "    print(\"▶ MiniRocketClassifier 학습 시작...\")\n",
    "    clf = minirocket()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # 4) 모델 저장\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    dump(clf, \"models/minirocket/minirocket.pkl\")\n",
    "    print(\"✅ 모델 저장 완료: models/minirocket/minirocket.pkl\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68dde9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_long(file_path: str):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    pivot = df.pivot_table(\n",
    "        index=[\"time\", \"Label\"],\n",
    "        columns=\"Variable\",\n",
    "        values=\"Value\",\n",
    "        aggfunc=\"first\"\n",
    "    ).sort_index()\n",
    "    X_raw = pivot.to_numpy(dtype=float)\n",
    "    y_raw = np.array([lab for (_, lab) in pivot.index], dtype=int)\n",
    "    classes = np.unique(y_raw)\n",
    "    label_mapping = {c: c for c in classes}\n",
    "    return X_raw, y_raw, label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986a0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/Et_H_CO.csv\"\n",
    "X_raw, y_raw, label_mapping = load_data_long(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8443df51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[629., 719., 331., ..., 572., 566., 700.],\n",
       "       [644., 737., 334., ..., 548., 584., 727.],\n",
       "       [665., 759., 342., ..., 598., 593., 739.],\n",
       "       ...,\n",
       "       [721., 815., 359., ..., 705., 675., 853.],\n",
       "       [730., 829., 359., ..., 656., 686., 865.],\n",
       "       [742., 843., 363., ..., 707., 694., 872.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f55a49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11880, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b9cdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, ..., 2, 3, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4d43a6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "243",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1863488\\2570333105.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"E:\\INHA\\BS\\sensor\\gpsig\\py\\std_scaler.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\KIMJUNHEE\\anaconda3\\envs\\gas_system_37\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KIMJUNHEE\\anaconda3\\envs\\gas_system_37\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[1;32mc:\\Users\\KIMJUNHEE\\anaconda3\\envs\\gas_system_37\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1083\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 243"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "scaler = joblib.load(r\"E:\\INHA\\BS\\sensor\\gpsig\\py\\std_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e16e1144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new scaler → models/gpsig_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# scripts/train_gpsig_scaler.py\n",
    "\n",
    "import os, glob, numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# 원시 CSV들이 모여 있는 폴더\n",
    "DATA_FOLDER = r\"E:\\INHA\\BS\\gas_system\\data\"\n",
    "LEN_EX      = 297\n",
    "EXPECTED_SENSORS = 8\n",
    "\n",
    "def load_one_csv(fpath):\n",
    "    df = pd.read_csv(fpath)\n",
    "    # drop 가능한 컬럼만\n",
    "    df = df.drop(\n",
    "        columns=[c for c in [\"Time(s)\", \"Temperature(oC)\", \"Relative_Humidity(%)\"]\n",
    "                 if c in df.columns],\n",
    "        errors='ignore'\n",
    "    )\n",
    "    df = df.groupby(df.index // 10).mean().iloc[-LEN_EX:, :]\n",
    "    return df.values\n",
    "\n",
    "def main():\n",
    "    # 1) 파일 패턴을 제한\n",
    "    pattern = os.path.join(DATA_FOLDER, \"[0-9][0-9][0-9]_*.csv\")\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No raw CSVs found in {DATA_FOLDER}\")\n",
    "\n",
    "    seqs = []\n",
    "    for f in files:\n",
    "        arr = load_one_csv(f)  # (297, sensor_count)\n",
    "        # sensor_count 확인\n",
    "        if arr.shape[1] != EXPECTED_SENSORS:\n",
    "            print(f\"Skipping {os.path.basename(f)}: sensors={arr.shape[1]}\")\n",
    "            continue\n",
    "        time = np.linspace(0, 1, LEN_EX)[:, None]\n",
    "        seq = np.hstack([time, arr])  # (297, EXPECTED_SENSORS+1)\n",
    "        seqs.append(seq)\n",
    "\n",
    "    # 2) 한 번 더 검증\n",
    "    if not seqs:\n",
    "        raise RuntimeError(\"No sequences collected after filtering.\")\n",
    "\n",
    "    # 3) 스케일러 학습 및 저장\n",
    "    all_samples = np.vstack(seqs)  # shape (n_files*297, 9)\n",
    "    scaler = StandardScaler().fit(all_samples)\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(scaler, \"models/gpsig_scaler.pkl\")\n",
    "    print(\"Saved new scaler → models/gpsig_scaler.pkl\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5afb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "SCALER_PATH = \"models/gpsig_scaler.pkl\"\n",
    "scaler = joblib.load(SCALER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a9ac17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec6f688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved class 1 → data\\class_1.csv\n",
      "Saved class 2 → data\\class_2.csv\n",
      "Saved class 3 → data\\class_3.csv\n",
      "Saved class 4 → data\\class_4.csv\n"
     ]
    }
   ],
   "source": [
    "# split_by_class.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def split_by_class(long_csv, out_dir=\"data\"):\n",
    "    # 1) 원본 긴 형식 CSV 로드\n",
    "    df = pd.read_csv(long_csv)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # 2) 레이블별 그룹핑 → 피벗 → 파일 저장\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for label, grp in df.groupby(\"Label\"):\n",
    "        pivot = grp.pivot(index=\"time\", columns=\"Variable\", values=\"Value\")\n",
    "        pivot = pivot.reset_index()\n",
    "        fname = os.path.join(out_dir, f\"class_{label}.csv\")\n",
    "        pivot.to_csv(fname, index=False)\n",
    "        print(f\"Saved class {label} → {fname}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_by_class(\"data/Et_H_CO.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e64efe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b7fd2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved expanded file to wavelet\\data_250418\\expanded\\000_Et_H_CO_n_dup.csv\n",
      "Saved expanded file to wavelet\\data_250418\\expanded\\002_Et_H_CO_H_dup.csv\n",
      "Saved expanded file to wavelet\\data_250418\\expanded\\008_Et_H_CO_L_dup.csv\n",
      "Saved expanded file to wavelet\\data_250418\\expanded\\028_Et_H_CO_M_dup.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"wavelet/data_250418\")\n",
    "OUT_DIR  = DATA_DIR / \"expanded\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "for csv_path in DATA_DIR.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # 마지막 컬럼 이름과 값을 가져옵니다.\n",
    "    last_col_name = df.columns[-1]\n",
    "    last = df[last_col_name]\n",
    "\n",
    "    # 4번 복사해서 새로운 컬럼으로 붙이기\n",
    "    for i in range(1, 5):\n",
    "        df[f\"{last_col_name}_dup{i}\"] = last\n",
    "\n",
    "    # 새 이름: 원본 파일명에 _dup 붙임\n",
    "    new_name = csv_path.stem + \"_dup\" + csv_path.suffix\n",
    "    out_path = OUT_DIR / new_name\n",
    "\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved expanded file to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4066d6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000_Et_H_CO_n.csv',\n",
       " '002_Et_H_CO_H.csv',\n",
       " '008_Et_H_CO_L.csv',\n",
       " '028_Et_H_CO_M.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('wavelet/data_250418')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d377c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gas_system_37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
